{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "775dekHVI9gl"
      },
      "source": [
        "# ** RETO (opcional): Implementación algoritmo de descenso de gradiente en problema con múltiples minínimos locales **\n",
        "**Facultad de ingeniería, departamento de Ingeniería Biomédica, Universidad de los Andes**\\\n",
        "**IBIO-2440 Programación científica**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FHIOLOzzJK2L"
      },
      "source": [
        "**Nombres de los integrantes**\n",
        "\n",
        "\n",
        "1.   David Tobón Molina\n",
        "2.   David Santiago Rodríguez Quiroga\n",
        "\n",
        "**Número del grupo**\n",
        "\n",
        "Grupo 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqexwZZjJUFQ"
      },
      "source": [
        "Considere el problema de optimización:\n",
        "\n",
        "\n",
        "\n",
        "> $\\min_x f(x)$ sujeto a $x\\in\\mathbb{R}^3$\n",
        "\n",
        "donde $f:\\mathbb{R^3}→\\mathbb{R}$ y $x=[x_1,x_2,x_3]^T$. Note que este es un problema de minmización sin restricciones en $\\mathbb{R}^3$. Se sabe que la función es derivable y posee varios minimizadores locales entre los cuales hayun minimizador global, todos con posiciones desconocidas. El objetivo del presente laboratorio bono es implementar y utilizar el algoritmo de descenso de gradiente para identificar la mayor cantidad de candidatos a minimizadores locales dentro de una región dada e identificar el posible minimizador global. \n",
        "\n",
        "*   Implemente su propia rutina del algoritmo de descenso de gradiente teniendo en cuenta que los minimizadores de la función están definida por $x_i ∈ [-5, 5]$ para cada $i = 1, …, 3$. Es decir, cada componente de $x$ està entre $-5$ y $5$. Defina un tamaño del salto $\\alpha$ y un parámetro de criterio de parada $ϵ$ que usted considere conveniente para resolver el problema. Estime el gradiente de la función evaluado en un punto de forma numérica (como se hizo en una práctica anterior), y bajo ninguna circunstancia utilice variables simbólicas.\n",
        "   \n",
        "*    Corra el algoritmo de descenso de gradiente al menos para 500 condiciones iniciales diferentes, y guarde las soluciones resultantes de cada corrida (ya sea definidas de forma aleatoria o haciendo un recorrido definido en la región donde se sabe están los minimizadores locales). Basados en estos resultados, realice una tabla donde incluya los valores aproximados de los candidatos a minimizadores locales (recuerden que cada candidato es un vector 3-dimensional), el candidato a minimizador global, y el respectivo número de iteraciones que el algoritmo de descenso de gradiente requirió para llegar a la respuesta.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Esta actividad funciona como un bono para la nota del primer parcial de los integrantes del grupo. La nota se asignará dependiendo de el correcto seguimiento de las instrucciones anteriores y la cantidad de minimizadores locales reales que su algoritmo encuentre. Cada grupo debe desarrollar su propia solución y no se permitirá copia entre grupos de todo el curso. Una falta ante esto se reportará inmediatamente ante el comité de ética de la facultad. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XK-Ktgm8D-O",
        "outputId": "4bc239e3-3584-4a5a-fdd3-7e8b78f7666c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mínimo de la función (-117.4984971113142, [-2.903534, -2.903534, -2.903534])\n"
          ]
        }
      ],
      "source": [
        "import benchmark_functions as bf\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "\n",
        "# func es el objeto creado con la funcion a minimizar\n",
        "func = bf.StyblinskiTang(n_dimensions=3)\n",
        "print(\"Mínimo de la función\", func.minimum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWsqQ0tq9D84",
        "outputId": "62b1b692-b907-4398-a9f1-2b240e161ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "375.0\n"
          ]
        }
      ],
      "source": [
        "# Dado un punto x0, func permite evaluar la función objetivo en x0 \n",
        "x0 = np.array([5.0, 5.0, 5.0]) \n",
        "f=func(x0)\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradiente incial: [172.50006704 172.50006704 172.50006704]\n"
          ]
        }
      ],
      "source": [
        "def numeric_gradient(xi, f, e=0.000001):\n",
        "\n",
        "    gradient_result = np.zeros(len(xi))\n",
        "\n",
        "    for i in range(len(xi)):\n",
        "        xi_k = np.copy(xi)\n",
        "        xi_k[i] = xi[i]+e\n",
        "        gradient_result[i] = (f(xi_k)-f(xi))/e\n",
        "\n",
        "    return gradient_result\n",
        "\n",
        "\n",
        "print(\"Gradiente incial:\", numeric_gradient(x0, func))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent(f, numeric_gradient_func, xi, n_max=500):\n",
        "\n",
        "    alpha = None\n",
        "    e = None\n",
        "    min_f = float(f(xi))\n",
        "    x_min = np.copy(xi)\n",
        "\n",
        "    # se prueban varios alphas y epsilons para encontrar el minimizador\n",
        "    for i in range(1, 10):\n",
        "        alpha = i/100\n",
        "        for j in range(1, 10):\n",
        "            \n",
        "            # algoritmo de descenso del gradiente\n",
        "            xk = np.copy(xi)\n",
        "            e = j/10\n",
        "            n = 0\n",
        "            stop = False\n",
        "\n",
        "            while not stop:\n",
        "\n",
        "                num_grad = numeric_gradient_func(xk, f)\n",
        "                xk1 = xk - (alpha*num_grad)\n",
        "\n",
        "                if n+1 >= n_max:\n",
        "                    stop = True\n",
        "                elif np.linalg.norm(xk1 - xk) <= e:\n",
        "                    stop = True\n",
        "                else:\n",
        "                    xk = np.copy(xk1)\n",
        "                    n += 1\n",
        "            \n",
        "            # revisar si el punto encontrado por el algoritmo es el mejor para la condición inicial dada\n",
        "            # actualizar los parámetros que obtuvieron el resultado\n",
        "            if float(f(xk)) < min_f:\n",
        "                min_f = float(f(xk))\n",
        "                x_min = np.copy(xk)\n",
        "                best_alpha = alpha\n",
        "                best_epsilon = e\n",
        "                best_n = n\n",
        "\n",
        "    return best_n, best_alpha, best_epsilon, x_min, min_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| x0            |   n_iteraciones |   alpha |   epsilon | x_min: mínimo local                |        f(x_min) |\n",
            "|:--------------|----------------:|--------:|----------:|:-----------------------------------|----------------:|\n",
            "| [-5. -5. -5.] |              11 |    0.03 |      0.10 | [-2.898378 -2.898378 -2.898378]    | -117.4971204334 |\n",
            "| [-5. -5.  5.] |              11 |    0.03 |      0.10 | [-2.898378 -2.898378 -2.903535]    | -117.4975793257 |\n",
            "| [-5.  5. -5.] |              11 |    0.03 |      0.10 | [-2.898378 -2.903535 -2.898378]    | -117.4975793257 |\n",
            "| [-5.  5.  5.] |              11 |    0.03 |      0.10 | [-2.898378 -2.903535 -2.903535]    | -117.4980382185 |\n",
            "| [ 5. -5. -5.] |              11 |    0.03 |      0.10 | [-2.903535 -2.898378 -2.898378]    | -117.4975793257 |\n",
            "| [ 5. -5.  5.] |              11 |    0.03 |      0.10 | [-2.903535 -2.898378 -2.903535]    | -117.4980382185 |\n",
            "| [ 5.  5. -5.] |              11 |    0.03 |      0.10 | [-2.903535 -2.903535 -2.898378]    | -117.4980382185 |\n",
            "| [5. 5. 5.]    |               9 |    0.03 |      0.10 | [-2.9038675 -2.9038675 -2.9038675] | -117.4984913419 |\n",
            "\n",
            "CANDIDATO A MINIMIZADOR GLOBAL:\n",
            "x_init = [5. 5. 5.]\n",
            "alpha = 0.03\n",
            "e = 0.1\n",
            "x = [-2.9038675 -2.9038675 -2.9038675]\n",
            "min_f = -117.49849134194517\n",
            "n = 9\n"
          ]
        }
      ],
      "source": [
        "x0_values = [-5, 5]\n",
        "x0 = np.zeros(3)\n",
        "dict_for_best_approx = {}\n",
        "table_headers = ['x0', 'n_iteraciones', 'alpha',\n",
        "                 'epsilon', 'x_min: mínimo local', 'f(x_min)']\n",
        "list_results = []\n",
        "min_f = None\n",
        "\n",
        "# probar el algoritmo para cada condición inicial y guardar información de cada resultado\n",
        "for i in range(len(x0_values)):\n",
        "    x0[0] = x0_values[i]\n",
        "    for j in range(len(x0_values)):\n",
        "        x0[1] = x0_values[j]\n",
        "        for k in range(len(x0_values)):\n",
        "            x0[2] = x0_values[k]\n",
        "            n, a, e, x_min, min_f = gradient_descent(\n",
        "                func, numeric_gradient, np.copy(x0))\n",
        "            dict_for_best_approx[min_f] = (np.copy(x0), n, a, e, x_min)\n",
        "            list_results.append([np.copy(x0), n, a, e, x_min, min_f])\n",
        "\n",
        "print(tabulate(list_results, headers=table_headers, tablefmt=\"grid\",\n",
        "      maxcolwidths=50, floatfmt=(None, None, '.2f', '.2f', None, '.10f')))\n",
        "\n",
        "# encontrar mejor aproximación\n",
        "for key in dict_for_best_approx:\n",
        "    if key < min_f:\n",
        "        min_f = key\n",
        "\n",
        "x_init, n, a, e, x_min = dict_for_best_approx[min_f]\n",
        "print(\n",
        "    f\"\\nCANDIDATO A MINIMIZADOR GLOBAL:\\nx_init = {x_init}\\nalpha = {a}\\ne = {e}\\nx = {x_min}\\nmin_f = {min_f}\\nn = {n}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
