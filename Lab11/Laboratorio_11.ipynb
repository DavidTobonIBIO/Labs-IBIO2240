{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl_j2KwtVuYT"
      },
      "source": [
        "# Laboratorio 11: \n",
        "**Facultad de ingeniería, departamento de Ingeniería Biomédica, Universidad de los Andes**\\\n",
        "**IBIO-2440 Programación científica**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dmnIao0gV6XJ"
      },
      "source": [
        "**Nombres de los integrantes**\n",
        "\n",
        "\n",
        "1.   David Tobón Molina\n",
        "2.   David Santiago Rodríguez Quiroga\n",
        "\n",
        "**Número del grupo**\n",
        "\n",
        "Grupo 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pkVvrCyYV-c2"
      },
      "source": [
        "En las últimas clases hemos visto las aplicaciones de la regresión en el modelamiento y filtrado de datos. Para obtener los coeficientes de la regresión partimos de un problema de optimización de mínimos cuadrados con la siguiente forma:\n",
        "\n",
        "\\begin{align*}\n",
        "  \\min_\\beta ||y-H\\beta||_2^2\n",
        "\\end{align*}\n",
        "\n",
        "Al ser resuelto analíticamente obtenemos los los valores de $\\beta$ que minimizan el problema a través de la fórmula:\n",
        "\\begin{align*}\n",
        "  \\beta^* =  (H^TH)^{-1}H^Ty\n",
        "\\end{align*}\n",
        "\n",
        "Existen algunos escenarios en los que utilizar la norma L2 al cuadrado para definir el problema inicial de optimización no es ventajoso. En el presente laboratorio vamos a explorar dichos escenarios. Una forma distinta de plantear el problema inicial es utilizar la norma L1 del error. Consideremos siguiente problema:\n",
        "\n",
        "\\begin{align*}\n",
        "  \\min_\\beta ||y-H\\beta||_1\n",
        " \\end{align*}\n",
        "\n",
        "Este problema también buscar reducir el error entre $y$ y $H\\beta$. Sin embargo, a diferencia de la optimización basada en mínimos cuadrados, este último método no puede ser resuelto de manera analítica, por lo que debemos utilizar las librerías de optimización de Python. \n",
        "\n",
        "\n",
        "\n",
        "1. Importe los datos del archivo *reg_1.xlsx*, la primera columna corresponde al eje x y la segunda al eje y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSA7AqTJl_2y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "from scipy.optimize import minimize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mat_data = loadmat('Reg1.mat')\n",
        "data_reg1_x = np.array(mat_data['x'][0])\n",
        "data_reg1_y = np.array(mat_data['y'][0])\n",
        "print(len(data_reg1_x))\n",
        "print(len(data_reg1_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9uexuhWDeY"
      },
      "source": [
        "2. Obtenga los coeficientes de la regresión lineal utilizando el algoritmo de mínimos cuadrados, utilice un polinomio de orden 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5XGM9zbo4JEK"
      },
      "outputs": [],
      "source": [
        "def build_H(data, n):\n",
        "    H = np.zeros((len(data), n+1))\n",
        "    \n",
        "    for i in range(len(H)):\n",
        "        for j in range(len(H[0])):\n",
        "            H[i][j] = data[i]**j\n",
        "    return H\n",
        "\n",
        "\n",
        "def get_betas(H, y):\n",
        "    Ht = H.transpose()\n",
        "    HtH = Ht.dot(H)\n",
        "    Hty = Ht.dot(y)\n",
        "    inv_HtH = np.linalg.inv(HtH)\n",
        "    return inv_HtH.dot(Hty)\n",
        "\n",
        "\n",
        "def calculate_regresion(H, betas):\n",
        "    regresion = np.dot(H, betas)\n",
        "    return regresion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.32473839  9.43353405 -4.83521534  0.83255594]\n"
          ]
        }
      ],
      "source": [
        "H = build_H(data_reg1_x, 3)\n",
        "betas_L2 = get_betas(H, data_reg1_y)\n",
        "regresion1 = calculate_regresion(H, betas_L2)\n",
        "print(betas_L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIbtDrJU4JN3"
      },
      "source": [
        "3. Ahora utilice la norma L1 para encontrar los coeficientes de la regresión. Utilice la función *minimize* de la librería *scipy.optimize*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def func_with_L1_norm(y, H, betas):\n",
        "#     return np.linalg.norm(y - np.dot(H, betas), ord=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5qcGEaAnjtb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h2rqn-k4QQh"
      },
      "source": [
        "4. Grafique la regresión obtenida junto con los datos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3OB9g-464Dh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMRjXkcE5H8B"
      },
      "source": [
        "5. Realice el mismo procedimiento de los puntos 1-4 con los datos del archivo _reg_2.xlsx_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id7Ok0wToO8g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IihJgGg8oRXw"
      },
      "source": [
        "6. Compare el método basado en la norma L1 vs. la norma L2. ¿Qué ocurre con las regresiones cuando hay *outliers*$^1 o anomalías$? Refiérase al efecto de penalización que ocurre en cada caso. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddw1WCJbo4lP"
      },
      "source": [
        " > 1. *En términos simples, un outlier es una medición extremadamente alta o baja en relación con el conjunto de datos con los que se está trabajando.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
